{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_6UUUJ8_JDZjgm2w4d5PEhKzLM27ncsa6zkKoJGUJBUoi8NzfrcAtVRnAQCo6DjkQb6VDBm\"\n",
    "PINECONE_API_ENV = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"C:\\\\Users\\\\LENOVO\\\\Desktop\\\\End-to-end-Medical-Chatbot-using-Llama2\\\\data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 5859\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.034477200359106064,\n",
       " 0.031023219227790833,\n",
       " 0.0067349993623793125,\n",
       " 0.02610897459089756,\n",
       " -0.03936201333999634,\n",
       " -0.16030248999595642,\n",
       " 0.06692397594451904,\n",
       " -0.006441470701247454,\n",
       " -0.04745051637291908,\n",
       " 0.014758859761059284,\n",
       " 0.07087533175945282,\n",
       " 0.05552757531404495,\n",
       " 0.019193289801478386,\n",
       " -0.026251329109072685,\n",
       " -0.010109508410096169,\n",
       " -0.026940548792481422,\n",
       " 0.022307483479380608,\n",
       " -0.022226618602871895,\n",
       " -0.14969265460968018,\n",
       " -0.01749304309487343,\n",
       " 0.007676269859075546,\n",
       " 0.05435226485133171,\n",
       " 0.003254482988268137,\n",
       " 0.03172600269317627,\n",
       " -0.0846213772892952,\n",
       " -0.02940598875284195,\n",
       " 0.051595672965049744,\n",
       " 0.04812409356236458,\n",
       " -0.003314794274047017,\n",
       " -0.05827922374010086,\n",
       " 0.041969284415245056,\n",
       " 0.022210709750652313,\n",
       " 0.1281888633966446,\n",
       " -0.022338956594467163,\n",
       " -0.011656241491436958,\n",
       " 0.06292833387851715,\n",
       " -0.032876305282115936,\n",
       " -0.09122610837221146,\n",
       " -0.03117538057267666,\n",
       " 0.05269957706332207,\n",
       " 0.047034792602062225,\n",
       " -0.08420304954051971,\n",
       " -0.0300561785697937,\n",
       " -0.020744718611240387,\n",
       " 0.009517784230411053,\n",
       " -0.003721792483702302,\n",
       " 0.007343328557908535,\n",
       " 0.03932436183094978,\n",
       " 0.09327410906553268,\n",
       " -0.0037885827478021383,\n",
       " -0.052742086350917816,\n",
       " -0.05805819109082222,\n",
       " -0.0068643949925899506,\n",
       " 0.005283229053020477,\n",
       " 0.08289298415184021,\n",
       " 0.019362755119800568,\n",
       " 0.0062844837084412575,\n",
       " -0.010330805554986,\n",
       " 0.009032356552779675,\n",
       " -0.037683770060539246,\n",
       " -0.04520607367157936,\n",
       " 0.02401638962328434,\n",
       " -0.0069442023523151875,\n",
       " 0.013491633348166943,\n",
       " 0.10005491971969604,\n",
       " -0.071683868765831,\n",
       " -0.02169504575431347,\n",
       " 0.03161846846342087,\n",
       " -0.05163463577628136,\n",
       " -0.08224768191576004,\n",
       " -0.06569331139326096,\n",
       " -0.00989536102861166,\n",
       " 0.0058163986541330814,\n",
       " 0.07355453819036484,\n",
       " -0.03405030816793442,\n",
       " 0.02488601580262184,\n",
       " 0.01448806282132864,\n",
       " 0.026457400992512703,\n",
       " 0.009656714275479317,\n",
       " 0.030217286199331284,\n",
       " 0.052803970873355865,\n",
       " -0.07535988092422485,\n",
       " 0.009897174313664436,\n",
       " 0.029836837202310562,\n",
       " 0.017555566504597664,\n",
       " 0.023091990500688553,\n",
       " 0.0019339261343702674,\n",
       " 0.0014001254457980394,\n",
       " -0.04717599228024483,\n",
       " -0.011194380931556225,\n",
       " -0.11420133709907532,\n",
       " -0.019812004640698433,\n",
       " 0.04026623070240021,\n",
       " 0.0021929889917373657,\n",
       " -0.07979222387075424,\n",
       " -0.02538231387734413,\n",
       " 0.09448292851448059,\n",
       " -0.02898111194372177,\n",
       " -0.14500252902507782,\n",
       " 0.23097743093967438,\n",
       " 0.027731100097298622,\n",
       " 0.032111480832099915,\n",
       " 0.031064996495842934,\n",
       " 0.04283281788229942,\n",
       " 0.06423777341842651,\n",
       " 0.03216314688324928,\n",
       " -0.00487674493342638,\n",
       " 0.055699415504932404,\n",
       " -0.03753236308693886,\n",
       " -0.0215055663138628,\n",
       " -0.028342649340629578,\n",
       " -0.028846941888332367,\n",
       " 0.03835311904549599,\n",
       " -0.01746867224574089,\n",
       " 0.05248536914587021,\n",
       " -0.07487605512142181,\n",
       " -0.03125976398587227,\n",
       " 0.021841533482074738,\n",
       " -0.03989564999938011,\n",
       " -0.008587109856307507,\n",
       " 0.026956573128700256,\n",
       " -0.04849550500512123,\n",
       " 0.011469874531030655,\n",
       " 0.029618263244628906,\n",
       " -0.020572170615196228,\n",
       " 0.013103901408612728,\n",
       " 0.028833406046032906,\n",
       " -3.194200554190157e-33,\n",
       " 0.0647820383310318,\n",
       " -0.018130239099264145,\n",
       " 0.051789943128824234,\n",
       " 0.12198273092508316,\n",
       " 0.028780145570635796,\n",
       " 0.0087220324203372,\n",
       " -0.07052115350961685,\n",
       " -0.01690724864602089,\n",
       " 0.040739696472883224,\n",
       " 0.042116180062294006,\n",
       " 0.02544722706079483,\n",
       " 0.03574619069695473,\n",
       " -0.04914474114775658,\n",
       " 0.002129100728780031,\n",
       " -0.015546616166830063,\n",
       " 0.05073058605194092,\n",
       " -0.048185259103775024,\n",
       " 0.03588063269853592,\n",
       " -0.004067067988216877,\n",
       " 0.10172475874423981,\n",
       " -0.05597001686692238,\n",
       " -0.010680987499654293,\n",
       " 0.011235800571739674,\n",
       " 0.09068652987480164,\n",
       " 0.004234495107084513,\n",
       " 0.035138655453920364,\n",
       " -0.009702835232019424,\n",
       " -0.09386523813009262,\n",
       " 0.09285551309585571,\n",
       " 0.00800494384020567,\n",
       " -0.007705416064709425,\n",
       " -0.052086714655160904,\n",
       " -0.012587959878146648,\n",
       " 0.0032668698113411665,\n",
       " 0.0060135237872600555,\n",
       " 0.007581581827253103,\n",
       " 0.010517198592424393,\n",
       " -0.08634552359580994,\n",
       " -0.06987876445055008,\n",
       " -0.0025338700506836176,\n",
       " -0.09097661077976227,\n",
       " 0.04688737168908119,\n",
       " 0.05207647755742073,\n",
       " 0.007193892262876034,\n",
       " 0.010903597809374332,\n",
       " -0.005229538772255182,\n",
       " 0.013937323354184628,\n",
       " 0.02196837216615677,\n",
       " 0.03420856222510338,\n",
       " 0.060224637389183044,\n",
       " 0.00011661044845823199,\n",
       " 0.014731992967426777,\n",
       " -0.07008922845125198,\n",
       " 0.02849903516471386,\n",
       " -0.027601642534136772,\n",
       " 0.010768351145088673,\n",
       " 0.03483092412352562,\n",
       " -0.022487878799438477,\n",
       " 0.00976911373436451,\n",
       " 0.07722778618335724,\n",
       " 0.021588344126939774,\n",
       " 0.11495622247457504,\n",
       " -0.06800113618373871,\n",
       " 0.023761043325066566,\n",
       " -0.015983911231160164,\n",
       " -0.01782696507871151,\n",
       " 0.06439494341611862,\n",
       " 0.03202573582530022,\n",
       " 0.05027022957801819,\n",
       " -0.005913649220019579,\n",
       " -0.03370799124240875,\n",
       " 0.017840316519141197,\n",
       " 0.01657339744269848,\n",
       " 0.06329654157161713,\n",
       " 0.03467720001935959,\n",
       " 0.04647345840930939,\n",
       " 0.09790614992380142,\n",
       " -0.006635494064539671,\n",
       " 0.02520708367228508,\n",
       " -0.0779883861541748,\n",
       " 0.01692640222609043,\n",
       " -0.0009457881096750498,\n",
       " 0.02247185818850994,\n",
       " -0.038253240287303925,\n",
       " 0.09570475667715073,\n",
       " -0.00535071175545454,\n",
       " 0.010469038039445877,\n",
       " -0.11524058878421783,\n",
       " -0.013262532651424408,\n",
       " -0.010709351859986782,\n",
       " -0.08311721682548523,\n",
       " 0.07327357679605484,\n",
       " 0.049392201006412506,\n",
       " -0.008994361385703087,\n",
       " -0.09584556519985199,\n",
       " 3.366149296434549e-33,\n",
       " 0.12493181973695755,\n",
       " 0.019349709153175354,\n",
       " -0.0582258477807045,\n",
       " -0.03598824888467789,\n",
       " -0.050746746361255646,\n",
       " -0.04566233605146408,\n",
       " -0.08260342478752136,\n",
       " 0.14819477498531342,\n",
       " -0.08842117339372635,\n",
       " 0.06027441471815109,\n",
       " 0.05103025957942009,\n",
       " 0.010303089395165443,\n",
       " 0.14121423661708832,\n",
       " 0.030813878402113914,\n",
       " 0.06103307381272316,\n",
       " -0.05285125970840454,\n",
       " 0.13664892315864563,\n",
       " 0.009189915843307972,\n",
       " -0.017325272783637047,\n",
       " -0.012848668731749058,\n",
       " -0.00799528043717146,\n",
       " -0.05098002031445503,\n",
       " -0.052350591868162155,\n",
       " 0.007593057118356228,\n",
       " -0.015166228637099266,\n",
       " 0.016960326582193375,\n",
       " 0.021270541474223137,\n",
       " 0.02055799402296543,\n",
       " -0.1200280711054802,\n",
       " 0.014461806043982506,\n",
       " 0.02675984986126423,\n",
       " 0.025330591946840286,\n",
       " -0.0427546426653862,\n",
       " 0.006768474821001291,\n",
       " -0.01445858832448721,\n",
       " 0.045261986553668976,\n",
       " -0.09147657454013824,\n",
       " -0.019439177587628365,\n",
       " -0.017833461984992027,\n",
       " -0.05491012707352638,\n",
       " -0.052641063928604126,\n",
       " -0.010459036566317081,\n",
       " -0.05201602354645729,\n",
       " 0.020892051979899406,\n",
       " -0.07997025549411774,\n",
       " -0.012111312709748745,\n",
       " -0.05773141607642174,\n",
       " 0.02317824214696884,\n",
       " -0.00803161971271038,\n",
       " -0.025989310815930367,\n",
       " -0.07995670288801193,\n",
       " -0.02072887495160103,\n",
       " 0.048817772418260574,\n",
       " -0.02038920484483242,\n",
       " -0.049176573753356934,\n",
       " 0.01415967382490635,\n",
       " -0.06362210959196091,\n",
       " -0.007807392161339521,\n",
       " 0.016431482508778572,\n",
       " -0.02568255178630352,\n",
       " 0.01338108442723751,\n",
       " 0.026248762384057045,\n",
       " 0.009978335350751877,\n",
       " 0.06322894990444183,\n",
       " 0.0026721502654254436,\n",
       " -0.006582724861800671,\n",
       " 0.016632026061415672,\n",
       " 0.03236645832657814,\n",
       " 0.03794251009821892,\n",
       " -0.036376021802425385,\n",
       " -0.006910946220159531,\n",
       " 0.00015967455692589283,\n",
       " -0.001633585779927671,\n",
       " -0.02727823331952095,\n",
       " -0.028038015589118004,\n",
       " 0.04968152567744255,\n",
       " -0.028867164626717567,\n",
       " -0.002418051240965724,\n",
       " 0.014774874784052372,\n",
       " 0.009764568880200386,\n",
       " 0.005797559395432472,\n",
       " 0.013486078940331936,\n",
       " 0.005567895248532295,\n",
       " 0.0372270792722702,\n",
       " 0.007232493255287409,\n",
       " 0.04015621170401573,\n",
       " 0.08150321245193481,\n",
       " 0.07199164479970932,\n",
       " -0.01305615995079279,\n",
       " -0.04288202524185181,\n",
       " -0.011011214926838875,\n",
       " 0.004897830542176962,\n",
       " -0.009229752235114574,\n",
       " 0.03519146889448166,\n",
       " -0.05103498697280884,\n",
       " -1.5714373802211412e-08,\n",
       " -0.08862444013357162,\n",
       " 0.0239093154668808,\n",
       " -0.01623874343931675,\n",
       " 0.03170047700405121,\n",
       " 0.027284175157546997,\n",
       " 0.05246879905462265,\n",
       " -0.04707096517086029,\n",
       " -0.058847445994615555,\n",
       " -0.0632082149386406,\n",
       " 0.04088853672146797,\n",
       " 0.049827940762043,\n",
       " 0.10655166208744049,\n",
       " -0.07450233399868011,\n",
       " -0.012495458126068115,\n",
       " 0.018370643258094788,\n",
       " 0.039474066346883774,\n",
       " -0.024797869846224785,\n",
       " 0.01451625395566225,\n",
       " -0.03706921264529228,\n",
       " 0.020015696063637733,\n",
       " -4.8594301915727556e-05,\n",
       " 0.00986657477915287,\n",
       " 0.024838784709572792,\n",
       " -0.05245809629559517,\n",
       " 0.029314136132597923,\n",
       " -0.08719196915626526,\n",
       " -0.014499745331704617,\n",
       " 0.026019057258963585,\n",
       " -0.018746383488178253,\n",
       " -0.07620513439178467,\n",
       " 0.035043250769376755,\n",
       " 0.10363949090242386,\n",
       " -0.02805054932832718,\n",
       " 0.012718234211206436,\n",
       " -0.07632549107074738,\n",
       " -0.018652433529496193,\n",
       " 0.02497669868171215,\n",
       " 0.08144541829824448,\n",
       " 0.06875890493392944,\n",
       " -0.0640566349029541,\n",
       " -0.08389392495155334,\n",
       " 0.061362382024526596,\n",
       " -0.033545587211847305,\n",
       " -0.10615341365337372,\n",
       " -0.04008050262928009,\n",
       " 0.03253019228577614,\n",
       " 0.07662486284971237,\n",
       " -0.07301613688468933,\n",
       " 0.0003375994274392724,\n",
       " -0.04087162762880325,\n",
       " -0.0757884681224823,\n",
       " 0.027527686208486557,\n",
       " 0.07462546974420547,\n",
       " 0.01771729253232479,\n",
       " 0.09121839702129364,\n",
       " 0.11022018641233444,\n",
       " 0.0005698270397260785,\n",
       " 0.05146332085132599,\n",
       " -0.014551276341080666,\n",
       " 0.03323199599981308,\n",
       " 0.023792244493961334,\n",
       " -0.022889798507094383,\n",
       " 0.03893755376338959,\n",
       " 0.030206795781850815]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index',\n            dimension=1536,\n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Initializing the Pinecone\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPINECONE_API_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPINECONE_API_ENV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m index_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenai\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Creating Embeddings for Each of The Text Chunks & storing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\genai\\lib\\site-packages\\pinecone\\deprecation_warnings.py:40\u001b[0m, in \u001b[0;36minit\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m    import os\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m    from pinecone import Pinecone, ServerlessSpec\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124m        )\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     33\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124minit is no longer a top-level attribute of the pinecone package.\u001b[39m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124mPlease create an instance of the Pinecone class instead.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[1;31mAttributeError\u001b[0m: init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index',\n            dimension=1536,\n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n"
     ]
    }
   ],
   "source": [
    "#Initializing the Pinecone\n",
    "pinecone.init(api_key=PINECONE_API_KEY,\n",
    "              environment=PINECONE_API_ENV)\n",
    "\n",
    "index_name=\"genai\"\n",
    "\n",
    "#Creating Embeddings for Each of The Text Chunks & storing\n",
    "docsearch=Pinecone.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using existing index: genai\n",
      "✅ Embeddings uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# ✅ STEP 1: Manually set credentials and index\n",
    "PINECONE_API_KEY = \"pcsk_6UUUJ8_JDZjgm2w4d5PEhKzLM27ncsa6zkKoJGUJBUoi8NzfrcAtVRnAQCo6DjkQb6VDBm\"  # replace with your real key\n",
    "PINECONE_ENV = \"us-east-1\"  # e.g., \"gcp-starter\" or \"aws-us-west-2\"\n",
    "index_name = \"genai\"  # e.g., \"medical-chatbot-index\"\n",
    "\n",
    "# ✅ STEP 2: Initialize Pinecone client and create index if needed\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "existing_indexes = [i.name for i in pc.list_indexes().index_list[\"indexes\"]]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,  # depends on your embedding model\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=PINECONE_ENV)\n",
    "    )\n",
    "    print(f\"✅ Created new index: {index_name}\")\n",
    "else:\n",
    "    print(f\"✅ Using existing index: {index_name}\")\n",
    "\n",
    "# ✅ STEP 3: Load embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ✅ STEP 4: Upload text chunks\n",
    "vectorstore = PineconeVectorStore.from_texts(\n",
    "    texts=[t.page_content for t in text_chunks],\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    "    namespace=\"\"  # optional\n",
    ")\n",
    "\n",
    "print(\"✅ Embeddings uploaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Purpose\n",
      "Allergy is a reaction of the immune system. Nor-\n",
      "mally, the immune system responds to foreign microor-\n",
      "ganisms and particles, like pollen or dust, by producing\n",
      "specific proteins called antibodies that are capable of\n",
      "binding to identifying molecules, or antigens, on the\n",
      "foreign organisms. This reaction between antibody and\n",
      "antigen sets off a series of reactions designed to protect\n",
      "the body from infection. Sometimes, this same series of\n",
      "\n",
      "2. reaction. Allergic rhinitis is characterized by an itchy,\n",
      "runny nose, often with a scratchy or irritated throat due\n",
      "to post-nasal drip. Inflammation of the thin membrane\n",
      "covering the eye (allergic conjunctivitis) causes redness,\n",
      "irritation, and increased tearing in the eyes. Asthma caus-\n",
      "es wheezing, coughing, and shortness of breath. Symp-\n",
      "toms of food allergies depend on the tissues most sensi-\n",
      "tive to the allergen and whether the allergen spread sys-\n",
      "\n",
      "3. KEY TERMS\n",
      "Allergen —A substance that provokes an allergic\n",
      "response.\n",
      "Anaphylaxis—Increased sensitivity caused by pre-\n",
      "vious exposure to an allergen that can result in\n",
      "blood vessel dilation (swelling) and smooth mus-\n",
      "cle contraction. Anaphylaxis can result in sharp\n",
      "blood pressure drops and difficulty breathing.\n",
      "Antibody —A specific protein produced by the\n",
      "immune system in response to a specific foreign\n",
      "protein or particle called an antigen.\n",
      "Antigen —A foreign protein to which the body\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# STEP: Load the same embedding model\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# STEP: Load the existing index from Pinecone\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=\"genai\",\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# STEP: Query the index\n",
    "query = \"What are Allergies\"\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "# STEP: Print the results\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"{i}. {doc.page_content}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers\n",
    "\n",
    "llm = CTransformers(\n",
    "    model=\"../model\",  # 👈 go up one level to access the model folder\n",
    "    model_file=\"llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "    model_type=\"llama\",\n",
    "    config={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.8,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " Allergies are abnormal immune system reactions to substances that are typically harmless, such as pollen, dust, mold, or certain foods. These substances can trigger a variety of symptoms, including itchy eyes, runny nose, congestion, coughing, wheezing, and difficulty breathing. In severe cases, allergies can lead to anaphylaxis, a life-threatening reaction that requires immediate medical attention.\n",
      "\n",
      "Sources:\n",
      "1. reaction. Allergic rhinitis is characterized by an itchy,\n",
      "runny nose, often with a scratchy or irritated throat due\n",
      "to post-nasal drip. Inflammation of the thin membrane\n",
      "covering the eye (allergic con...\n",
      "2. reaction. Allergic rhinitis is characterized by an itchy,\n",
      "runny nose, often with a scratchy or irritated throat due\n",
      "to post-nasal drip. Inflammation of the thin membrane\n",
      "covering the eye (allergic con...\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import BaseRetriever\n",
    "from typing import List, Any\n",
    "from langchain_core.documents import Document\n",
    "from pydantic import Field\n",
    "\n",
    "class CustomRetriever(BaseRetriever):\n",
    "    vectorstore: Any = Field()\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        return self.vectorstore.similarity_search(query, k=2)\n",
    "\n",
    "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        return await self.vectorstore.asimilarity_search(query, k=2)\n",
    "\n",
    "retriever = CustomRetriever(vectorstore=docsearch)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n",
    "\n",
    "response = qa({\"query\": \"What are allergies?\"})\n",
    "\n",
    "print(\"Answer:\\n\", response[\"result\"])\n",
    "print(\"\\nSources:\")\n",
    "for i, doc in enumerate(response[\"source_documents\"], 1):\n",
    "    print(f\"{i}. {doc.page_content[:200]}...\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :  Acne is a common skin condition characterized by inflamed red bumps, blackheads, and whiteheads on the face, chest, and back. It occurs when the pores in the skin become clogged with dead skin cells, oil, and bacteria, leading to infection and inflammation. Acne can cause emotional distress and impact self-esteem, especially among teenagers and young adults. Treatment options include topical creams and gels, oral antibiotics, and hormonal therapy for more severe cases.\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_20536\\4216317267.py\", line 3, in <module>\n",
      "    result=qa({\"query\": user_input})\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 181, in __call__\n",
      "    run_id = config.get(\"run_id\")\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 175, in __call__\n",
      "    ) -> Dict[str, Any]:\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py\", line 131, in _call\n",
      "    run_manager: Optional[CallbackManagerForChainRun] = None,\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 320, in run\n",
      "    callbacks configuration and some input/output processing.\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 181, in __call__\n",
      "    run_id = config.get(\"run_id\")\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 175, in __call__\n",
      "    ) -> Dict[str, Any]:\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py\", line 106, in _call\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py\", line 165, in combine_docs\n",
      "    \"\"\"Get default document variable name, if not provided.\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\llm.py\", line 252, in predict\n",
      "    return outputs\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 181, in __call__\n",
      "    run_id = config.get(\"run_id\")\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 175, in __call__\n",
      "    ) -> Dict[str, Any]:\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\llm.py\", line 92, in _call\n",
      "    return_final_only: bool = True\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\llm.py\", line 102, in generate\n",
      "    def input_keys(self) -> List[str]:\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\llms\\base.py\", line 141, in generate_prompt\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\llms\\base.py\", line 234, in generate\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\llms\\base.py\", line 178, in _generate_helper\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\llms\\base.py\", line 165, in _generate_helper\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\llms\\base.py\", line 557, in _generate\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\llms\\ctransformers.py\", line 102, in _call\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\ctransformers\\llm.py\", line 432, in _stream\n",
      "    for token in self.generate(\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\ctransformers\\llm.py\", line 390, in generate\n",
      "    self.eval(tokens, batch_size=batch_size, threads=threads)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\ctransformers\\llm.py\", line 307, in eval\n",
      "    status = self.ctransformers_llm_batch_eval(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input Prompt:\")\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
